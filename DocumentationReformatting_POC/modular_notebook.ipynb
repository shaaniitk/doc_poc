{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modular Document Processing System\n",
    "\n",
    "Following the exact workflow from modular_refactor.py with all functionality in one consolidated processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the consolidated processor\n",
    "from modular_document_processor import main\n",
    "import os\n",
    "\n",
    "print(\"Modular Document Processing System loaded\")\n",
    "print(\"Following exact modular_refactor.py workflow\")\n",
    "print(f\"MISTRAL_API_KEY: {'Set' if os.getenv('MISTRAL_API_KEY') else 'Not set'}\")\n",
    "print(f\"HUGGING_FACE_TOKEN: {'Set' if os.getenv('HUGGING_FACE_TOKEN') else 'Not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single Document Processing (LLM Reformatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "source_file = 'bitcoin_whitepaper.tex'\n",
    "template = 'bitcoin_paper'  # 'bitcoin_paper' or 'academic_paper'\n",
    "output_format = 'latex'\n",
    "chunking_strategy = 'semantic'\n",
    "\n",
    "print(f\"Processing: {source_file}\")\n",
    "print(f\"Template: {template}\")\n",
    "print(f\"This will make actual LLM API calls for each section...\")\n",
    "\n",
    "# Process document (following exact modular_refactor.py workflow)\n",
    "result = main(\n",
    "    source=source_file,\n",
    "    template=template,\n",
    "    output_format=output_format,\n",
    "    chunking_strategy=chunking_strategy\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessing completed!\")\n",
    "print(f\"Final document: {result['final_document']}\")\n",
    "print(f\"Session path: {result['session_path']}\")\n",
    "print(f\"Sections processed: {result['processed_sections']}\")\n",
    "print(f\"LLM calls made: {result['analysis']['llm_calls']}\")\n",
    "print(f\"Quality score: {result['analysis']['quality_score']:.1f}/100\")\n",
    "\n",
    "# Store for next cell\n",
    "single_result = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Augmentation (Combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for document combination\n",
    "base_document = single_result['final_document'] if 'single_result' in locals() else 'bitcoin_whitepaper.tex'\n",
    "additional_document = 'blockchain_security.tex'\n",
    "combine_strategy = 'smart_merge'  # 'smart_merge' or 'simple_append'\n",
    "\n",
    "print(f\"Combining documents:\")\n",
    "print(f\"  Base: {base_document}\")\n",
    "print(f\"  Additional: {additional_document}\")\n",
    "print(f\"  Strategy: {combine_strategy}\")\n",
    "\n",
    "# Combine documents (following exact modular_refactor.py workflow)\n",
    "augment_result = main(\n",
    "    source=base_document,\n",
    "    source2=additional_document,\n",
    "    combine_strategy=combine_strategy,\n",
    "    output_format=output_format\n",
    ")\n",
    "\n",
    "print(f\"\\nAugmentation completed!\")\n",
    "print(f\"Combined document: {augment_result['final_document']}\")\n",
    "print(f\"Session path: {augment_result['session_path']}\")\n",
    "print(f\"Quality score: {augment_result['analysis']['quality_score']:.1f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'single_result' in locals():\n",
    "    print(\"Single Document Processing:\")\n",
    "    print(f\"  Final document: {single_result['final_document']}\")\n",
    "    print(f\"  Sections processed: {single_result['processed_sections']}\")\n",
    "    print(f\"  LLM calls: {single_result['analysis']['llm_calls']}\")\n",
    "    print(f\"  Quality score: {single_result['analysis']['quality_score']:.1f}/100\")\n",
    "    print(f\"  Session path: {single_result['session_path']}\")\n",
    "\n",
    "if 'augment_result' in locals():\n",
    "    print(f\"\\nDocument Augmentation:\")\n",
    "    print(f\"  Combined document: {augment_result['final_document']}\")\n",
    "    print(f\"  Quality score: {augment_result['analysis']['quality_score']:.1f}/100\")\n",
    "    print(f\"  Session path: {augment_result['session_path']}\")\n",
    "\n",
    "# Show session files\n",
    "if 'single_result' in locals():\n",
    "    session_path = single_result['session_path']\n",
    "    if os.path.exists(session_path):\n",
    "        files = os.listdir(session_path)\n",
    "        print(f\"\\nGenerated files in {session_path}:\")\n",
    "        for file in sorted(files):\n",
    "            file_path = os.path.join(session_path, file)\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  {file}: {size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available Configuration Options\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"Templates:\")\n",
    "print(\"  - bitcoin_paper: Bitcoin whitepaper structure (12 sections)\")\n",
    "print(\"  - academic_paper: Standard academic format (6 sections)\")\n",
    "\n",
    "print(\"\\nLLM Providers:\")\n",
    "print(\"  - mistral: Mistral AI (fast, reliable)\")\n",
    "print(\"  - openai: OpenAI (high quality)\")\n",
    "print(\"  - huggingface: Hugging Face (free tier available)\")\n",
    "\n",
    "print(\"\\nCombination Strategies:\")\n",
    "print(\"  - smart_merge: Intelligently merge matching sections\")\n",
    "print(\"  - simple_append: Append all sections from second document\")\n",
    "\n",
    "print(\"\\nChunking Strategies:\")\n",
    "print(\"  - semantic: LLM-enhanced intelligent chunking\")\n",
    "print(\"  - regex_only: Pattern-based chunking only\")\n",
    "\n",
    "print(\"\\nOutput Formats:\")\n",
    "print(\"  - latex: LaTeX document format\")\n",
    "print(\"  - markdown: Markdown format\")\n",
    "\n",
    "# Show current config\n",
    "try:\n",
    "    import yaml\n",
    "    with open('config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\"\\nCurrent Configuration:\")\n",
    "    print(f\"  LLM Provider: {config['llm']['provider']}\")\n",
    "    print(f\"  Model: {config['llm']['model']}\")\n",
    "    print(f\"  Temperature: {config['llm']['temperature']}\")\n",
    "    print(f\"  Max tokens: {config['llm']['max_tokens']}\")\nexcept:\n    print(\"\\nUsing default configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Advanced Usage Examples\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"Example 1: Academic paper processing\")\n",
    "print(\"result = main(\")\n",
    "print(\"    source='research_paper.tex',\")\n",
    "print(\"    template='academic_paper',\")\n",
    "print(\"    output_format='latex'\")\n",
    "print(\")\")\n",
    "\n",
    "print(\"\\nExample 2: Document combination\")\n",
    "print(\"result = main(\")\n",
    "print(\"    source='paper1.tex',\")\n",
    "print(\"    source2='paper2.tex',\")\n",
    "print(\"    combine_strategy='smart_merge'\")\n",
    "print(\")\")\n",
    "\n",
    "print(\"\\nExample 3: Custom configuration\")\n",
    "print(\"# Edit config.yaml to change LLM provider:\")\n",
    "print(\"llm:\")\n",
    "print(\"  provider: 'huggingface'\")\n",
    "print(\"  model: 'mistralai/Mistral-7B-Instruct-v0.3'\")\n",
    "\n",
    "print(\"\\nWorkflow Summary:\")\n",
    "print(\"1. Load LaTeX file\")\n",
    "print(\"2. Extract and chunk content\")\n",
    "print(\"3. Assign chunks to document skeleton\")\n",
    "print(\"4. Process each section with LLM\")\n",
    "print(\"5. Aggregate final document\")\n",
    "print(\"6. Generate analysis and reports\")\n",
    "\n",
    "print(\"\\nThis follows the exact modular_refactor.py workflow!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}